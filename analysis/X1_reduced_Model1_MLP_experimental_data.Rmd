---
title: "ANNI in Tensorflow"
author: "Samantha Rubo"
date: "2022-08-10"
---


```{r, message=FALSE}
library(keras)
library(mlbench)
library(dplyr)
library(magrittr)
library(neuralnet)
library(ggplot2)
library(data.table)
library(purrr)
library(tidyr)
```


### Input-Tabelle laden (aus A3_Tabelle_erstellen.RMD)
```{r}
#rm(list = ls())
files2 <- c(
    "../data/derived_data/input_tabelle_2020_2023_20240328_20cm_complete.csv",
    "../data/derived_data/input_tabelle_2020_2023_20240328_20cm_complete_DLR.csv"
    # "../data/derived_data/input_tabelle_2020_2023_20240403_lstm_geeignet_20cm_complete.csv",
    # "../data/derived_data/input_tabelle_2020_2023_20240403_lstm_geeignet_20cm_complete_DLR.csv"
)

data0 <- map_df(files2, 
                ~data.table::fread(.x, sep = ";", dec = ".")
) %>% as_tibble() 

columns_with_nFK <- grep("nFK", names(data0), value = TRUE)

# Step 2: Filter rows where all 'nFK' columns have values <= 100
data0 <- data0 %>% 
    filter(across(all_of(columns_with_nFK), ~ . <= 100))

names(data0)
```


```{r}
names_x <- c("B0020_nFK_prozent_Vortag",            # Nur MLP, nicht LSTM
             "B2040_nFK_prozent_Vortag",            # Nur MLP, nicht LSTM
             "B4060_nFK_prozent_Vortag",            # Nur MLP, nicht LSTM
             "tage_seit_aussaat", 
             "Tmean_gradC", 
     #Sens        "Tmean_th9_25_gradC", 
     #Sens        "Tmin_gradC", 
     #Sens        "Tmax_gradC", 
             "relLuftfeuchte_mean_prozent", 
             #"relLuftfeuchte_min_prozent", # laut Olden unwichtig
             #"relLuftfeuchte_max_prozent", # s.o.
     #Sens        "globalstrahlung_Wh_m2", 
              "windgeschwindigkeit_m_s", 
     #Sens         "tageslicht_h", 
     #Sens         "tageslicht_h_th9", 
             "Tmean_gradC_sum",             # s.o.
             "Tmean_th9_25_gradC_sum",      # s.o.
             "globalstrahlung_Wh_m2_sum",   # s.o.
             "niederschlag_mm_sum",         # s.o.
     #Sens         "tageslicht_h_sum",            # s.o.
             "tageslicht_h_th9_sum",        # s.o.
             "Ton_prozent",
     #Sens        "Schluff_prozent",
             "Sand_prozent",
     #Sens      "C_org_prozent",
             "ibi", 
             "irmi",
             "wasser_input_Vortag" ## bei LSTM Tageswert statt Vortageswert
)

names_y <- c(
    "B0020_nFK_prozent", 
    "B2040_nFK_prozent",
    "B4060_nFK_prozent"
)
data1 <- data0 %>% select(all_of(c(names_y,names_x))) 
```

## Skalierungs-Daten einlesen:
```{r}
scaling_data <- fread("../data/derived_data/Models_paper/All_scaling_data_20230328.csv")

names_all <- scaling_data$parameter
m <- scaling_data$m
s <- scaling_data$s

names(m) <- names_all
names(s) <- names_all
```

## DF skalieren
```{r}
df_scaled <- scale(data1[,c(names_y, names_x)], 
                   center = m[c(names_y, names_x)], 
                   scale = s[c(names_y, names_x)])
```


# ANNI: 
## Trainings- und Test-Daten einteilen:
```{r}
set.seed(123)
ind <- sample(2, nrow(df_scaled), replace = T, prob = c(.7, .3))

#X definieren:
training <- df_scaled[ind==1,names_x]
test <- df_scaled[ind==2, names_x]

#Target definieren:
trainingtarget <- df_scaled[ind==1, names_y] 
testtarget <- df_scaled[ind==2, names_y]
```


#Keras initiieren: Input-Layer und Output-Layer definieren
#A ) Sequential Model
```{r, eval=TRUE}
model <- keras_model_sequential()

#Modell weiter anpassen:
#Lernrate ändern, etc.
model %>%
    layer_dense(units = 128, activation = 'sigmoid', input_shape = c(length(names_x))) %>%
    layer_dropout(rate=0.1)  %>%
    layer_dense(units = 64, activation = 'sigmoid')  %>%
    layer_dropout(rate=0.1)  %>%
    layer_dense(units = length(names_y))

#Loss-Function beschreiben
model %>% compile(loss = 'mse',
                  optimizer = 'rmsprop', 
                  metrics = c('accuracy','mae')) 

```

#B) Functional Model:
```{r, eval=FALSE}
# inputs <- layer_input(shape = c(length(names_x)))
# 
# # outputs compose input + dense layers
# predictions <- inputs %>%
#     layer_dense(units = 100, activation = 'sigmoid') %>%
#     layer_dropout(rate=0.05)  %>%
#     layer_dense(units = 50, activation = 'sigmoid') %>%
#     layer_dropout(rate=0.05)  %>%
#     layer_dense(units = length(names_y))
# 
# # create model
# model <- keras_model(inputs = inputs, outputs = predictions)
# 
# # compile model
# model %>% compile(
#     optimizer = 'rmsprop',
#     loss = 'mse',
#     #    metrics = c('mae', 'accuracy')
#     metrics = c('mae')
# )
```

#Model trainieren:
```{r, message=FALSE}
earlystopping = callback_early_stopping(monitor = "loss", 
                                        min_delta = 0.001, 
                                        patience = 5, 
                                        mode = "min", 
                                        restore_best_weights = TRUE                                            
)

model %>%          
    fit(training,trainingtarget, 
        epochs = 150,
        batch_size = 32*2, #2000,
        validation_split = 0.2, 
        callbacks = earlystopping
    )
```

# make Predictions 
```{r}
model %>% evaluate(test, testtarget)

pred <- model %>% predict(rbind(test, training), stateful = FALSE)
# pred <- model %>% predict(training, stateful = FALSE) 

#rescale to normal nFK-values:
sy <- matrix(s[names_y], nrow = nrow(pred), ncol = length(names_y), byrow = T)
my <- matrix(m[names_y], nrow = nrow(pred), ncol = length(names_y), byrow = T)
pred_nFK <- pred * sy + my

test_y_nFK <- as.matrix(rbind(testtarget, trainingtarget)) * sy + my
# test_y_nFK <- as.matrix(trainingtarget) * sy + my  
```

# Gütemaße:
```{r}
## package performance
 lm1 <- map(1:length(names_y), ~summary(lm(pred_nFK[,.x]~test_y_nFK[,.x])))
# rmse1 <- map(1:length(names_y), ~round(performance::rmse(model = lm1[[.x]]), 2))
# rmse_text <- paste0( paste0("RMSE y", 1:length(names_y), ": "), rmse1, collapse = "\n")

## singulär berechnet
rmse1 <- round(colMeans(sqrt((test_y_nFK-pred_nFK)^2)), 2)
ncol2 = 3
rmse_text <- paste0( paste0("RMSE y", 1:ncol2, ": "), rmse1, collapse = "\n")

cat(rmse_text)
cat("\n\n")
cat(map_chr(1:length(names_y), ~paste0("R2 y",.x ," = ", round(lm1[[.x]]$r.squared, 3), "\n")))
```

# Ergebnis zu Tabelle zusammenführen:
```{r}
labels1 <- c("00-20 cm", 
             "20-40 cm", 
             "40-60 cm")

ergebnis_df_erstellen <- function(measured=test_y_nFK, predicted=pred_nFK, labels1=labels1
){
    x1 <- measured %>% as.data.frame() %>%
        tidyr::pivot_longer(cols = everything(), values_to = "measured", names_to = "depth")
    
    y1 <- predicted %>% as.data.frame() %>%
        tidyr::pivot_longer(cols = everything(), values_to = "predicted", names_to = "depth") %>% select(predicted)
    result1 <- bind_cols(x1, y1) %>%
        mutate(across("depth", ~factor(.,labels= labels1 ))) %>% 
        group_by(depth) %>% 
        mutate(x= 1:n() ,
               diff_meas_pred = abs(measured - predicted),
               diff_big = ifelse(diff_meas_pred > 5, predicted, NA))
    
    return(result1)
}

result <- ergebnis_df_erstellen(measured=test_y_nFK, predicted=pred_nFK, labels1=labels1)
```

# Ergebnis plotten:
```{r, warning=FALSE}
source("Functions/plot_measured_predicted_lm.R")

plot_measured_predicted_lm(linear_model = lm1, data = result) +
    scale_x_continuous(limits = c(0,150)) +
    scale_y_continuous(limits = c(0,150))
```





#Modell speichern:
```{r, eval=FALSE}
filepath_tf <- "../data/derived_data/Models_paper/X1_reduced_Model1_MLP_experimental_data"
 #keras::save_model_tf(model, filepath = filepath_tf, overwrite = TRUE)
```





