---
title: "Stationsdaten DEutschlandweit extrahieren für ANNI"
author: "Samantha Rubo"
date: "2022-10-25"
---

#Pakete laden:
```{r, message=FALSE}
library(data.table)
library(rdwd) ## Paket fuer DWD-Daten-Import!
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(lubridate)
library(stringr)
```

# Welche Parameter werden benötigt?
## Header (Parameter) für ANNI:
```{r}
parameter_anni <- fread(
    "../data/derived_data/input_tabelle_2020_2022_20220808_complete.csv", 
    sep = ";", nrows = 1, header = FALSE) %>% t
parameter_anni
```
# Bei DWD sind folgende Stations-Daten verfügbar:
```{r}
# PARAMETER # KUERZEL # ORDNER
# Temperatur --> min, max, mean, threshold, sum # TMK, TXK, TNK # kl
# rel. Luftfeuchte --> min, max, mean,# UPM: nur Tagesmittel# kl, moisture
# Globalstrahlung --> sum1, sum2# # solar
# Windgeschwindigkeit # FM# kl
# Niederschlag# RSK # kl
# Tageslichtstunden (berechnen) --> tag, threshold, sum # --- # ---
```


Die Daten der nFK stammen vom DWD. 
"Da die Messung der Bodenfeuchte sehr aufwendig und fehlerbehaftet ist, wird sie mittlerweile nicht mehr gemessen, sondern berechnet." (https://www.dwd.de/DE/leistungen/bodenfeuchte_dl/bodenfeuchtedl.html, 31.10.22)
Die Bodenfeuchte ist verfügbar in 10-cm-Schritten bis 60 cm Tiefe unter Gras bei lehmigen Sand (leichter Boden) oder sandigem Lehm (schwerer Boden).
(Wie weit zurück reichen die Daten?? Davon hängt ab, bis wann die Stationsdaten der anderen Parameter geladen werden)

# Server ansprechen und Index der Bodenfeuchte-Daten erstellen:
```{r, rows.print = 25}
dbase <- "ftp://opendata.dwd.de/climate_environment/CDC/derived_germany"
soilIndex <- indexFTP(folder="soil/daily", base=dbase, dir=locdir())
soilIndex <- createIndex(soilIndex, base=dbase, dir=locdir())
#"res" and "var" are inverted in the derived_germany folder!
colnames(soilIndex)[1:2] <- c("var", "res")
soilIndex
#soilIndex %>% select(per, id) %>% filter(!is.na(id)) 
```

## "Stations_id" der Stationen mit Bodenfeuchte für "recent" und "historical" auslesen.
```{r}
id_nFK <- soilIndex %>% select(per, id) %>% 
    filter(!is.na(id)) %>%
    group_by(id) %>%
    summarise(nn = n()) %>% 
    filter(nn == 2) %>% pull(id)
```

# Welche Wetter-Daten sind verfügbar an den Stationen?

## Meta-Index des DWD nutzen:
```{r}
meta1 <- rdwd:::metaIndex
str(meta1)
```

## Welche Parameter sind generell verfügbar?
```{r}
meta1$var %>% unique()
# wir brauchen "kl": "Klima". Aber welche Parameter sind an der jeweiligen Station gemessen?
# zusätzlich "solar", da Globalstrahlung nicht in Klima-Daten vorhanden ist.
```

## Auswahl der Stationen in Abhängigkeit der größten gemeinsamen Schnittmenge an gemessenen Parametern
```{r}
#Auswahl für Globalstrahlung unter var = "solar":
meta1 %>% filter(var == "solar") %>% 
    group_by(res, per) %>%
    summarise(n=n(), .groups = "drop")

# 10_minutes-Resolution: 325 Stationen 
# hourly:47 Stationen
# daily46 Stationen
# per = "recent" hat nur 10-minute resolution!! 
# --> Diese 325 Stationen als Auswahl nehmen und selber Tages-Summen berechnen
```
## Auswahl für Klimadaten unter var = "kl":
```{r}
meta1 %>% filter(var == "kl") %>% 
    group_by(res, per) %>%
    summarise(n=n(), .groups = "drop")
# daily resolution hat die meisten Einträge (#1346) 
```
## Auswahl für rel. Luftfeuchte unter var = "moisture": (für min und max-Berechnung)
```{r}
meta1 %>% filter(var == "moisture") %>% 
    group_by(res, per) %>%
    summarise(n=n(), .groups = "drop")
# subdaily resolution (#1186) hat die meisten Einträge
# hourly hat #712 einträge
```
## Auswahl für Windgeschwindigkeit unter var = "wind": (für min und max-Berechnung)
```{r}
meta1 %>% filter(var == "wind") %>% 
    group_by(res, per) %>%
    summarise(n=n(), .groups = "drop")
# subdaily resolution (#1156) hat die meisten Einträge
# hourly hat #525 einträge
```
## #Funktion zum auslesen der passenden Stations-IDs (für "recent" und "historical")
```{r}
pull_station_id <- function(.var, .res){
    meta1 %>% 
        select(Stations_id, res, var, per) %>%
        filter(var == .var & res == .res) %>% 
        group_by(Stations_id, per) %>% 
        summarise(n =n(), .groups = "drop") %>%
        pivot_wider(id_cols = Stations_id, names_from = per, values_from = n) %>% 
        filter(if_any(c("recent", "historical"), ~!is.na(.))) %>% 
        pull(Stations_id) %>% unique
}
```

```{r}
# Stations-ID für Parameters auslesen
id_globalstrahlung <- pull_station_id(.var = "solar", .res = "10_minutes") 
id_klima <- pull_station_id(.var = "kl", .res = "daily") 
id_moisture <- pull_station_id(.var = "moisture", .res = "subdaily") 
id_wind <- pull_station_id(.var = "wind", .res = "subdaily") 
```

```{r}
#Gemeinsame Schnittmenge der IDs filtern:
id_complete <- data.frame(id = c(id_globalstrahlung, id_klima, id_moisture, id_wind)) %>%
    group_by(id) %>% summarise(n=n()) %>% 
    filter(n == 4) %>% pull(id)
```
318 Stationen liefern alle Parameter zu heutigen und historischen Werten.

## Verwendbare Wetterstationen plotten (Stations-Auswahl == alle Daten vorhanden)
```{r}
Stations_Auswahl <- meta1 %>% filter(Stations_id %in% id_complete) %>%
    select(Stations_id, Stationsname, geoBreite, geoLaenge) %>%
    filter(!duplicated(.)) %>%
    group_by(Stations_id, Stationsname) %>%
    summarise(across(c("geoBreite", "geoLaenge"), ~mean(.)), .groups = "drop")
```

### Deutschland-Grenzen laden:
```{r}
# #Daten laden:
# germany <- geodata::gadm(country = "Germany", level = 0, path = tempdir(), resolution = 2)
# library(raster)
# #In SpatialPolygonsDataFrame konvertieren
# germany_sp <- as(germany, "Spatial")
# #als Shapefile speichern
# rgdal::writeOGR(obj=germany_sp, dsn = "../data/derived_data/Germany_boundaries", layer = "Germany_shapefile",
#driver="ESRI Shapefile") # this is in equal area projection
# #Alle germany-Versionen aus Workspace entfernen
# #rm(list = ls()[grepl(x = ls(), pattern = "germany")])
# detach("package:raster", unload = TRUE)

#Gespeichertes shapefile einlesen:
germany_sp <- rgdal::readOGR(dsn = "../data/derived_data/Germany_boundaries", layer = "Germany_shapefile")
```

```{r, message=FALSE}
ggplot() +
    geom_polygon(data = germany_sp,
                 aes(x = long, y = lat, group = group),
                 colour = "grey10", fill = "#fff7bc") +
    geom_point(data = Stations_Auswahl,
               aes(x = geoLaenge, y = geoBreite),
               alpha = .5, size = 1.5) +
    coord_map() +
    theme_bw() +
    xlab("Longitude") + ylab("Latitude") +
    labs(title = "DWD Weather Stations", subtitle = "inlcuding all parameters")
```






# Daten der Stationsauswahl laden:

## Wetterdaten (unter Ordner "kl" = Klima) 
Hier überspringen. Bereits einmal ausgeführt und Daten gespeichert.
```{r eval=FALSE, include=TRUE}
#Select data from the DWD CDC FTP Server
link <- selectDWD(id = Stations_Auswahl$Stations_id, 
                  res="daily", var="kl", per="", current=FALSE, meta = FALSE)
#per = "": beides
link
#var="kl" = Klima-Daten (alle gemessenen Parameter)

#Download data from the DWD CDC FTP Server --> 150 MB. uncomment to load!
# file <- dataDWD(url = link, read=FALSE, 
# dir = "../data/raw_data/DWDdata/kl_Klima", 
# quiet=TRUE, force=NA)

#if file couldn't be downloaded, remove from list
file <- file[file.exists(file)]
#file <- list.files(path = "../data/raw_data/DWDdata/", full.names = TRUE, pattern = ".zip")

#Process data from the DWD CDC FTP Server to a data.frame
clim <- readDWD(file, varnames=TRUE,fread=TRUE) 
#fread = FALSE for full Windows compatibility
#str(clim)
```

#passende Parameter auswählen:
```{r, eval=FALSE}
clim_filtered <- purrr::map(clim, 
                            ~dplyr::select(.data = .,
                                           # nFK_0010,                         # Alle nFK aus nFK-Tabelle
                                           # nFK_1020, 
                                           # nFK_2030, 
                                           # nFK_3040, 
                                           # nFK_4050, 
                                           # nFK_5060, 
                                           # nFK_0010_Vortag,
                                           # nFK_1020_Vortag,
                                           # nFK_2030_Vortag,
                                           # nFK_3040_Vortag,
                                           # nFK_4050_Vortag,
                                           # nFK_5060_Vortag,
                                           # tage_seit_aussaat,                # Mittelwert für Gras?
                                           Tmean_gradC = TMK.Lufttemperatur,
                                           # Tmean_th9_25_gradC,               #berechnen
                                           Tmin_gradC = TNK.Lufttemperatur_Min,
                                           Tmax_gradC =TXK.Lufttemperatur_Max,
                                           relLuftfeuchte_mean_prozent = UPM.Relative_Feuchte,
                                           # relLuftfeuchte_min_prozent,       #berechnen
                                           # relLuftfeuchte_max_prozent,       #berechnen
                                           # globalstrahlung_Wh_m2,            #in "solar" Ordner --> Tagessumme berechnen
                                           # windgeschwindigkeit_m_s,          #ueberall NA --> eigener Download s.o.
                                           # tageslicht_h,                     #berechnen
                                           # tageslicht_h_th9,                 #berechnen
                                           # Tmean_gradC_sum,                  #berechnen
                                           # Tmean_th9_25_gradC_sum,           #berechnen
                                           # globalstrahlung_Wh_m2_sum,        #berechnen
                                           niederschlag_mm_sum = RSK.Niederschlagshoehe, ##herausnehmen für ANNI?? 
                                           wasser_input_mm = RSK.Niederschlagshoehe#, ##stattdessen Parameter hinzugefügt für ANNI?? 
                                           # tageslicht_h_sum,                 #berechnen
                                           # tageslicht_h_th9_sum,             #berechnen
                                           # Ton_prozent,                      #aus nFK-Tabelle
                                           # Schluff_prozent,                  #aus nFK-Tabelle
                                           # Sand_prozent,                     #aus nFK-Tabelle
                                           # C_org_prozent,                    #aus nFK-Tabelle
                                           # ibi,                              #Mittelwert für Gras?
                                           # irmi,                             #Mittelwert für Gras?
                                           # wasser_input_Vortag,              #berechnen
                            ))

rm(clim)
```

Info zum Niederschlag: "Das Zeitintervall der täglichen Niederschlagshöhe ist als 6 Uhr bis 6
Uhr Folgetag definiert." 
(Quellen: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/kl/recent/BESCHREIBUNG_obsgermany_climate_daily_kl_recent_de.pdf)

#gefilterte Daten als RDS speichern:
```{r, eval=FALSE}
#Speichern der Wetterdaten als RDS
# map(1:length(clim_filtered),
#     ~saveRDS(object = clim_filtered[[.]],
#         file = paste0("../data/derived_data/DWD_data/kl_Klima/",
#                       names(clim_filtered)[.],
#                       ".rds"))
# )
```



## Globalstrahlung (unter Ordner "solar") 
Die Einheit der Daten ist J/cm²
Hier überspringen. Bereits einmal ausgeführt und Daten gespeichert.
```{r eval=FALSE, include=TRUE, max.print = 10}
#Select data from the DWD CDC FTP Server
link <- selectDWD(id = Stations_Auswahl$Stations_id[11:319], 
                  res="10_minutes", var="solar", per=c("recent", "historical"), current=FALSE, meta = FALSE)
link

#Download data from the DWD CDC FTP Server uncomment to load!
# file <- dataDWD(url = link, read=FALSE,
#                 dir = "../data/raw_data/DWDdata/solar_Globalstrahlung/zipped/",
#                 quiet=TRUE, force=NA)

#if file couldn't be downloaded, remove from list
file <- file[file.exists(file)]
#file <- list.files(path = "../data/raw_data/DWD_data/solar_Globalstrahlung/zipped", full.names = TRUE, pattern = ".zip")
```

#unzip alle Daten über Terminal: (schnelleres Einlesen im nächsten Schritt)
```{bash eval=FALSE, include=TRUE}
unzip ../data/raw_data/DWD_data/solar_Globalstrahlung/zipped/\*.zip -d ../data/raw_data/DWD_data/solar_Globalstrahlung/unzipped/
```






# Einlesen der gedownloadeden GS-Daten
```{r eval=FALSE, include=TRUE}
idx <- 1:100
#Process data from the DWD CDC FTP Server to a data.frame
solar <- readDWD(file[idx], varnames=TRUE,fread=F) 
#str(solar[[1]])
```

#Einlesen mit data.table
```{r, eval=FALSE}
file_list_solar_unzipped <- list.files(path = "../data/raw_data/DWD_data/solar_Globalstrahlung/unzipped/", 
                                       full.names = TRUE, pattern = ".txt")
solar2 <- map(file_list_solar_unzipped,
              ~fread(file = ., 
                     header=T, sep=";", select = c("MESS_DATUM", "GS_10"), showProgress = TRUE
              ))
```


#Datensätze mit Werten zur GS filtern
```{r, eval=FALSE ,warning=FALSE}
solar3 <- map_df(.x = 1:length(solar2), 
                 ~pull(.data = solar2[[.x]], GS_10) %>%
                     ifelse(.<= -998,NA,.) %>%
                     range(., na.rm = TRUE)%>% 
                     as.matrix %>% t %>% 
                     as.data.frame %>% 
                     setNames(c("min_GS", "max_GS"))
) %>% 
    mutate(idx = 1:n()) %>%
    filter(min_GS != Inf)

# solar3
# nrow(solar3) 
```

```{r, eval=FALSE}
solar4 <- solar2[solar3$idx]
names(solar4) <- paste0("Auswahl_", basename(file_list_solar_unzipped[solar3$idx]))
```

#Bereinigte Daten speichern
```{r, eval=FALSE}
# map(1:length(solar4),
#     ~fwrite(x = solar4[[.]], 
#             file = paste0("../data/derived_data/DWD_data/solar_Globalstrahlung/",names(solar4)[.]))
# )
```

```{r}
rm(list = c(ls()[grepl(x = ls(), pattern = "id_|solar|file")]))
gc()
```


# Ausgewählte GS-Daten einlesen:
```{r}
file_list <- list.files("../data/derived_data/DWD_data/solar_Globalstrahlung/", full.names = TRUE)
solar <- map(file_list, ~fread(.))
```

```{r}
# #Anzahl Beobachtungen an einem Tag bei 10-Min Intervall
# anz <- 60/10 * 24 #144 Beobachtungen
# 
# x <- solar[[5]] %>%
#     mutate_at("GS_10", ~ifelse(. == -999, NA, .)) %>% 
#     
#     mutate_at("MESS_DATUM", ~as_datetime(as.character(.),
#                                          format = "%Y%m%d%H%M")) %>%
#     #nicht alle Daten sind in 10-Minuten-Incrementen. Hier auffüllen, um später Tages-Summe korrekt zu bilden
#     full_join(data.frame(MESS_DATUM = seq(from = min(.$MESS_DATUM), to = max(.$MESS_DATUM), by = (60*10)))) %>%
#     arrange(MESS_DATUM) %>% 
#     mutate(datum = as.Date(MESS_DATUM),
#            stunde = hour(MESS_DATUM)) %>% 
#     
#     # Hälfte der Einträge am Tag müssen vorhanden sein, sonst Tag löschen:
#     group_by(datum) %>%
#     mutate(n = sum(!is.na(GS_10), na.rm=TRUE)) %>%
#     # mutate(time_increment = c(NA, diff(MESS_DATUM))) 
#     ## jetzt sollte alles in 10 Minuten-Abständen sein!
#     # x$time_increment %>% unique() %>% as.numeric() %>% sort()
#     
#     filter(n > anz/2) %>% 
#     
#     #Fehlende Werte approximieren
#     group_by(datum) %>%
#     mutate_at("GS_10", ~round(zoo::na.approx(.,  na.rm=FALSE, rule = 2),1))
# x
# 
# plot(x$MESS_DATUM, x$GS_10, pch = 16, col = alpha("black", 0.5))
# lines(x$MESS_DATUM, x$GS_10)
```




```{r}
#Anzahl Beobachtungen an einem Tag bei 10-Min Intervall
anz <- 60/10 * 24 #144 Beobachtungen
```

#long und lat auslesen:
```{r}
id_extract_all <- str_extract(string = basename(file_list), pattern ="[[:digit:]]++.txt") %>% 
    str_extract(., pattern = "[[:digit:]]++") %>% as.numeric 

id_extract_unique <- id_extract_all %>% unique

long_lat <- meta1 %>% filter(Stations_id %in% id_extract_unique) %>% 
    select(Stations_id, geoBreite, geoLaenge) %>% 
    filter(!duplicated(.)) %>%
    group_by(Stations_id) %>%
    summarise_all(~round(mean(.), 2))
```


# Nacht: Globalstrahlung == 0 als Fixpunkt berechnen. 
Um Fehlwerte bei Nacht-Messungen zu eliminieren.
Output: Tabelle mit sunrise und dusk für jeden Messtag
```{r}
GS0_nacht <- function(idx){
    output <- suncalc::getSunlightTimes(date = unique(
        solar[[idx]] %>% 
            filter(GS_10 >= 0) %>%
            mutate_at("MESS_DATUM", 
                      ~as.Date(as_datetime(as.character(.),
                                           format = "%Y%m%d%H%M"))) %>% 
            pull(MESS_DATUM)
    ), 
    lat = long_lat %>% filter(Stations_id == id_extract_all[idx]) %>% pull(geoBreite),
    lon = long_lat %>% filter(Stations_id == id_extract_all[idx]) %>% pull(geoLaenge)
    ) %>% 
        select(sunrise, dusk) %>% 
        mutate_all(~floor_date(., unit = "10 minutes")) %>% 
        pivot_longer(cols = everything(), values_to = "MESS_DATUM") %>%
        mutate(GS_nacht = 0) %>%
        select(-name)
    
    output
}

list_df_GS0_nacht <- map(1:length(solar), ~GS0_nacht(.))
list_df_GS0_nacht[[5]]
```


#Einzelne Tabellen bereinigen: 
mit NA-gefüllte Tage entfernen
Tage mit weniger als der Hälfte der Einträge löschen
alles auf 10-Minuten Intervalle korrigieren
Sonnenauf- und Unergang mit GS_10 = 0 hinzufügen
Fehlende Werte approximieren (interpolieren)

```{r}
tidy_solar_df <- function(idx){
    output <- solar[[idx]] %>%
        mutate_at("GS_10", ~ifelse(. == -999, NA, .)) %>% 
        
        #Fehlende Werte entfernen:
        filter(!is.na(GS_10)) %>%
        mutate_at("MESS_DATUM", ~as_datetime(as.character(.),
                                             format = "%Y%m%d%H%M")) %>%
        
        #nicht alle Daten sind in 10-Minuten-Incrementen. Hier auffüllen, um später Tages-Summe korrekt zu bilden
        full_join(map_df(unique(as.Date(.$MESS_DATUM)), 
                         ~data.frame(
                             MESS_DATUM = seq(
                                 from = floor_date(as.POSIXct(.),"1 day") , 
                                 to = floor_date(as.POSIXct(.),"1 day") +(60*60*24) - (60*10), 
                                 by = 60*10))
        )
        ) %>%
        
        arrange(MESS_DATUM) %>% 
        mutate(datum = as.Date(MESS_DATUM),
               stunde = hour(MESS_DATUM)) %>% 
        
        # Hälfte der Einträge am Tag müssen vorhanden sein, sonst Tag löschen:
        group_by(datum) %>%
        mutate(n = sum(!is.na(GS_10), na.rm=TRUE)) %>%
        # mutate(time_increment = c(NA, diff(MESS_DATUM))) 
        ## jetzt sollte alles in 10 Minuten-Abständen sein!
        # x$time_increment %>% unique() %>% as.numeric() %>% sort()
        
        filter(n > anz/2) %>% 
        
        #sunset und dusk auf GS == 0 setzen, um Fehlmessungen in der NAcht im nächsten Schritt korrekt zu interpolieren.
        ungroup() %>%
        left_join(list_df_GS0_nacht[[idx]],  by = "MESS_DATUM") %>%
        mutate_at("GS_10", ~ifelse(is.na(GS_nacht), ., 0)) %>%
        
        
        #Fehlende Werte approximieren
        group_by(datum) %>%
        mutate_at("GS_10", ~round(zoo::na.approx(.,  na.rm=FALSE, rule = 2),1))
    
    output
}

```

```{r, eval = FALSE}
solar_tidy <- map(1:length(solar), ~tidy_solar_df(.))
#solar_tidy2 <- solar_tidy
```


# Aufsummieren der 10-Minuten-Intervalle Globalstrahlung und Konvertierung in Wh m-2: Tagessumme GS
Daten sind in J cm-2 == Ws cm-2, da
1 W = 1 J/s
Konvertieren in Wh m-2 --> Ws cm-2  /  (60*60)  * 10000

```{r}
zeit_intervall <- 60*60 # 1 Stunde?
cm2 <- 100*100

solar_daily <- map(solar_tidy, 
                   ~group_by(.data = ., datum) %>% 
                       summarise(globalstrahlung_Wh_m2 = sum(GS_10 / zeit_intervall , na.rm = TRUE) * cm2
                       ) %>%
                       filter(globalstrahlung_Wh_m2 != 0))

```


# Vergleich mit Globalstrahlung (Wh/m2) im Jahresverlauf 2021 am Queckbrunnerhof
Dient der Plausibilitäts-Analyse der Einheits-Konvertierung
```{r}
#Daten Queckbrunnerhof einlesen:
df <- fread("../../GeoSenSys2020/Data_2020/Messdaten/Queckbrunnerhof/Wetterstation_Queckbrunnerhof/Wetter_Schifferstadt_2020_taeglich.csv", dec = ",") 
df <- df %>% select(datum_wetter = Tag, globalstrahlung_Wh_m2 = SUM_GS200) %>%
    mutate_at("datum_wetter", ~as.Date(., format = "%d.%m.%Y"))

idx = 403 # Mannheim in meiner Liste

ggplot(df, aes(datum_wetter, globalstrahlung_Wh_m2, col = "Queckbrunnerhof \n(DLR Station)")) + 
    geom_point() + geom_line() +
    geom_line(data = solar_daily[[idx]] %>% 
                  filter(between(datum,as.Date("2020-01-01"),as.Date("2020-12-31"))), 
              aes(datum, globalstrahlung_Wh_m2, col = "Mannheim \n(DWD Stations_id 05906)")) +
    scale_color_discrete("Wetter-Station:") + 
    theme_bw() + 
    theme(panel.grid = element_blank(), legend.position = "bottom")
```
Die Daten der beiden Stationen (Entfernung < 20 km) stimmen nahezu überein. Die Konvertierung ist plausibel.


```{r}
# map(solar_daily, ~range(.$datum, na.rm = TRUE))
# idx = 250
map(1:length(solar_daily), 
    ~fwrite(x = solar_daily[[.x]], 
            file = paste0("../data/derived_data/DWD_data/solar_Globalstrahlung/Xdaily/", 
                          "globalstrahlung_Wh_m2", 
                          range(solar_daily[[.x]]$datum, na.rm = TRUE) %>% 
                              format.Date("%Y%m%d") %>% 
                              paste0(collapse = "_"),
                          "Stations_id_", id_extract_all[idx], ".csv", collapse = "_")
    ))
```




#Bodenfeuchte-Daten laden:
Übersichtskarte der Stationen: https://opendata.dwd.de/climate_environment/CDC/help/stations_map_soil.png

"historical": Tägliche Werte sei 1991-01-01 bis Ende letztes Jahr
"recent": Tägliche Werte dieses Jahres
```{r}
soil_link <- selectDWD(id = 2597, res="", var="", per="", base=dbase, findex=soilIndex)

# download Daten
soil_data <- dataDWD(soil_link, base=dbase, dir=locdir())
```

#Alle Werte in eine lange Tabelle:
```{r}
df_final <- bind_rows(soil_data)
```


#Plot der Bodentemp für 2022
```{r}
#Daten umformen (in lange Tabelle)
clim_melted <- tidyr::pivot_longer(df_final %>%
                                       select(Datum,
                                              BF10, BF20, BF30, BF40, BF50, BF60) %>%
                                       filter(Datum > "2021-12-31"),
                                   cols = BF10:BF60,
                                   names_to = "Variable",
                                   values_to = "value") %>%
    mutate(Tiefe = substring(Variable, 3, nchar(Variable))) %>%
    mutate_at("Tiefe",
              ~as.numeric(.)) %>%
    mutate_at("Variable",
              ~factor(., levels = c("BF10", "BF20", "BF30", "BF40", "BF50", "BF60")))


#Plot:
ggplot(clim_melted, aes(Datum, value, col=as.factor(Tiefe))) +
    geom_rect(aes(xmin = as_date(-Inf), xmax = as_date(Inf),
                  ymin = 60, ymax = 90, fill = "Ausreichend"), color = NA)+
    geom_rect(aes(xmin = as_date(-Inf), xmax = as_date(Inf),
                  ymin = 0, ymax = 60, fill = "Unterversorgt"), color = NA)+
    geom_line()+
    ylab("Nutzbare Feldkapazität (%)") +
    theme_bw() +
    theme(panel.grid = element_blank()) +
    scale_fill_manual("Wasser-\nVersorgunszustand",
                      values = c("Ausreichend"="gray90", "Unterversorgt"="gray80"))

```
#Daten als CSV speichern:
```{r}
#fwrite(x = df_final, "Bodentemp_feuchte_Schifferstadt_1991_2022.csv", sep = ";")
```






